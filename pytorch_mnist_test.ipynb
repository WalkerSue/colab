{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_mnist_test.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPVfd2b9kA1dwyVJOCPMBC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WalkerSue/colab/blob/torch/pytorch_mnist_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3faYj0Izf9Jt"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn, optim\r\n",
        "import torchvision\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "class LeNet5(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        # 定义第一层卷积层，1个输入通道，6个输出通道，5*5的filter,28+2+2=32 padding 填充\r\n",
        "        # 左右，上下填充padding=2\r\n",
        "        # MNIST图像大小是28，LeNet大小是32\r\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\r\n",
        "        # 定义第二层卷积层\r\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\r\n",
        "        # 定义三个全连接层\r\n",
        "        self.fc1 = nn.Linear(16*5*5, 120)\r\n",
        "        self.fc2 = nn.Linear(120, 84)\r\n",
        "        self.fc3 = nn.Linear(84, 10)\r\n",
        "    # 向前传播    \r\n",
        "    def forward(self, x):\r\n",
        "        # 先卷积，再用relu激活函数，然后再最大值池化\r\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\r\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\r\n",
        "        # num_flat_features = 16*5*5\r\n",
        "        # 摊平\r\n",
        "        x = x.view(-1, self.num_flat_features(x))\r\n",
        "        \r\n",
        "        #第一个全连接\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = self.fc3(x)\r\n",
        "        return x\r\n",
        "    \r\n",
        "    def num_flat_features(self, x):\r\n",
        "        size = x.size()[1:]\r\n",
        "        num_features = 1\r\n",
        "        for s in size:\r\n",
        "            num_features = num_features * s\r\n",
        "        return num_features\r\n",
        "\r\n",
        "import torchvision.datasets as datasets\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import  torchvision.transforms as transforms\r\n",
        "\r\n",
        "#超参数定义\r\n",
        "EPOCH = 10\r\n",
        "BATCH_SIZE = 64\r\n",
        "LR = 0.001\r\n",
        "\r\n",
        "train_data = datasets.MNIST(root='./mnist/', train=True, transform=transforms.ToTensor(), download=True)\r\n",
        "test_data = datasets.MNIST(root='./mnist/', train=False, transform=transforms.ToTensor(), download=True)\r\n",
        "\r\n",
        "test_x = test_data.test_data.type(torch.FloatTensor)[:2000]/255.\r\n",
        "test_y = test_data.test_labels.numpy()[:2000]\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "print (\"Train Data Size:\", train_data.train_data.size())\r\n",
        "print (\"Train Label Size:\", train_data.train_labels.size())\r\n",
        "\r\n",
        "plt.imshow(train_data.train_data[0].numpy(), cmap=\"gray\")\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# 使用DataLoader 进行分批\r\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\r\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)\r\n",
        "\r\n",
        "# 创建model\r\n",
        "model = LeNet5()\r\n",
        "# 定义损失函数\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "# 定义优化器\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\r\n",
        "\r\n",
        "# device\r\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
        "model.to(device)\r\n",
        "\r\n",
        "# 训练\r\n",
        "total_step = len(train_loader)\r\n",
        "for epoch in range(EPOCH):\r\n",
        "    for i, data in enumerate(train_loader):\r\n",
        "        inputs, labels = data\r\n",
        "        # 可能使用GPU\r\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\r\n",
        "        # forward\r\n",
        "        outputs = model(inputs)\r\n",
        "        # 计算损失函数\r\n",
        "        loss = criterion(outputs, labels)\r\n",
        "        # 清空上一轮梯度\r\n",
        "        optimizer.zero_grad()\r\n",
        "        # 反向传播\r\n",
        "        loss.backward()\r\n",
        "        # 参数更新\r\n",
        "        optimizer.step()\r\n",
        "        if (i+1) % 100 == 0:\r\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \r\n",
        "                   .format(epoch+1, EPOCH, i+1, total_step, loss.item()))\r\n",
        "            \r\n",
        "\r\n",
        "# 保存模型\r\n",
        "# torch.save(model, \"mnist_lenet.pt\")\r\n",
        "torch.save({'state_dict': model.state_dict()}, \"mnist_lenet.pt\")\r\n",
        "# torch.save(model.state_dict(), \"mnist_lenet.pt\")\r\n",
        "# 模型加载\r\n",
        "# model = torch.load(\"mnist_lenet.pt\")\r\n",
        "model = LeNet5() # 实例化\r\n",
        "checkpoint = torch.load('mnist_lenet.pt')\r\n",
        "model.load_state_dict(checkpoint['state_dict']) # 加载权重\r\n",
        "# model.load_state_dict(torch.load('mnist_lenet.pt')) \r\n",
        "\r\n",
        "# 测试\r\n",
        "model.to(device)\r\n",
        "model.eval()\r\n",
        "correct = 0\r\n",
        "total = 0\r\n",
        "\r\n",
        "for data in test_loader:\r\n",
        "    images, labels = data\r\n",
        "    images, labels = images.to(device), labels.to(device)\r\n",
        "    # forward\r\n",
        "    out = model(images)\r\n",
        "    _, predicted = torch.max(out.data, 1)\r\n",
        "    total = total + labels.size(0)\r\n",
        "    correct = correct + (predicted==labels).sum().item()\r\n",
        "    \r\n",
        "# 输出测试的准确率\r\n",
        "print (\"Test Data Accurary:\",100*correct/total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sn2gNGIkeMF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqwEcpkaju1V"
      },
      "source": [
        "# 测试\r\n",
        "model.to(device)\r\n",
        "model.eval()\r\n",
        "correct = 0\r\n",
        "total = 0\r\n",
        "\r\n",
        "for data in test_loader:\r\n",
        "    images, labels = data\r\n",
        "    images, labels = images.to(device), labels.to(device)\r\n",
        "    # forward\r\n",
        "    out = model(images)\r\n",
        "    _, predicted = torch.max(out.data, 1)\r\n",
        "    total = total + labels.size(0)\r\n",
        "    correct = correct + (predicted==labels).sum().item()\r\n",
        "    \r\n",
        "# 输出测试的准确率\r\n",
        "print (\"Test Data Accurary:\",100*correct/total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0m3ZBHNkvdz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}